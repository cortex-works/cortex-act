{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training: Fine-tuning xLAM-2 for Banking Agent\n",
    "\n",
    "This notebook demonstrates the fine-tuning process for the xLAM-2-1b-fc-r model on banking agent tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_preparation import BankingDatasetProcessor\n",
    "from training import BankingAgentTrainer, ModelArguments, DataArguments\n",
    "import torch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data processor\n",
    "processor = BankingDatasetProcessor()\n",
    "\n",
    "# Prepare dataset\n",
    "output_dir = processor.prepare_for_training(\"../data/processed\")\n",
    "print(f\"Dataset prepared in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training arguments\n",
    "model_args = ModelArguments(\n",
    "    model_name_or_path=\"Salesforce/xLAM-2-1b-fc-r\",\n",
    "    use_lora=True,\n",
    "    lora_r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "data_args = DataArguments(\n",
    "    data_path=\"../data/processed\",\n",
    "    max_length=2048\n",
    ")\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(f\"Model: {model_args.model_name_or_path}\")\n",
    "print(f\"LoRA enabled: {model_args.use_lora}\")\n",
    "print(f\"Max length: {data_args.max_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = BankingAgentTrainer(model_args, data_args)\n",
    "\n",
    "# Setup model and tokenizer\n",
    "trainer.setup_model_and_tokenizer()\n",
    "\n",
    "print(\"Trainer initialized successfully!\")\n",
    "print(f\"Model device: {trainer.model.device}\")\n",
    "print(f\"Model dtype: {trainer.model.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load and Inspect Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "datasets = trainer.load_dataset()\n",
    "\n",
    "print(\"Dataset sizes:\")\n",
    "for split, dataset in datasets.items():\n",
    "    print(f\"{split}: {len(dataset)} examples\")\n",
    "\n",
    "# Show sample training example\n",
    "print(\"\\nSample training example:\")\n",
    "sample = datasets['train'][0]\n",
    "print(f\"Text length: {len(sample['text'])} characters\")\n",
    "print(f\"Scenario ID: {sample['scenario_id']}\")\n",
    "print(f\"Persona Index: {sample['persona_index']}\")\n",
    "print(f\"\\nFirst 500 characters:\")\n",
    "print(sample['text'][:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Start Training (Optional - can be resource intensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This cell is optional and can be resource-intensive\n",
    "# Uncomment to run actual training\n",
    "\n",
    "# # Initialize wandb (optional)\n",
    "# wandb.init(project=\"xlam-banking-agent\", name=\"notebook-training\")\n",
    "\n",
    "# # Start training\n",
    "# output_dir = \"../models/xlam-banking-agent\"\n",
    "# trained_model = trainer.train(output_dir)\n",
    "\n",
    "# print(f\"Training completed! Model saved to {output_dir}\")\n",
    "\n",
    "print(\"Training cell is commented out to avoid resource usage.\")\n",
    "print(\"Uncomment the code above to run actual training.\")\n",
    "print(\"Alternatively, use the command line script: bash scripts/run_training.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Training Monitoring Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Monitoring Tips:\")\n",
    "print(\"1. Monitor GPU memory usage with: nvidia-smi\")\n",
    "print(\"2. Watch training logs in real-time: tail -f logs/training.log\")\n",
    "print(\"3. Use wandb dashboard for metrics visualization\")\n",
    "print(\"4. Expected training time: 2-4 hours on single GPU\")\n",
    "print(\"5. Watch for overfitting - validation loss should decrease\")\n",
    "\n",
    "print(\"\\nRecommended hyperparameters for different setups:\")\n",
    "print(\"- Single GPU (8GB): batch_size=2, gradient_accumulation=8\")\n",
    "print(\"- Single GPU (16GB): batch_size=4, gradient_accumulation=4\")\n",
    "print(\"- Multi-GPU: Increase batch_size proportionally\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}